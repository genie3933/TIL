- 웹 데이터 수집 시 주의할 점 (수집해도 되는 페이지인가?)
    - 로봇 배제 표준 robots.txt 확인하기
    - 저작권 확인하기
    - 무리한 네트워크 요청하지 않기
- 데이터 수집하기
    - 데이터 수집 방법
    - 수집할 url 찾기
    - requests를 통한 http 요청
    - pandas 코드로 데이터 수집하기
    - Json 타입 데이터 수집
    - 중복데이터 제거하기

---

## 웹 데이터 수집 시 주의할 점

### 로봇 배제 표준 확인

- 로봇 배제 표준이란 웹 사이트에 로봇이 접근하는 것을 방지하기 위한 규약을 말한다
- 일반적으로 접근 제한에 대한 설명을 robots.txt에 기술한다
- 이 규약은 권고안이기 때문에 접근 방지 설정을 했다고 해도, 다른 사람들이 그 파일에 접근 할 수는 있다
- 그러므로 불법으로 데이터를 수집하거나 영업, 저작권 침해를 한다면 법적 재재를 받을 수 있으니 데이터 수집 시 이 부분을 주의할 필요가 있다
- 수집전 robots.txt 확인하는 방법

    url주소/robots.txt

출처: [https://ko.wikipedia.org/wiki/로봇_배제_표준](https://ko.wikipedia.org/wiki/%EB%A1%9C%EB%B4%87_%EB%B0%B0%EC%A0%9C_%ED%91%9C%EC%A4%80)

### 저작권 확인하기

ex) 로봇의 검색결과 수집에 대한 네이버 정책

[https://policy.naver.com/rules/search_policy.html](https://policy.naver.com/rules/search_policy.html)

### 무리한 네트워크 요청하지 않기

- 여러 페이지를 한꺼번에 읽어오면 DDOS 공격으로 의심받을 수 있다
- 때문에 time.sleep( )을 사용하여 간격을 두고 가져오는 것이 좋다

## 데이터 수집하기

### 데이터 수집 방법

- 수집하고자 하는 페이지의 URL 확인한다
- requests를 통해 URL에 접근한다
- response.status_code가 200 OK라면, 정상 응답 (raise_for_status( )로도 확인 가능)
- request의 response 값에서 response.text (html 문서)만 받아온다
- 받아온 html 문서를 bs를 사용해 해석한다
- [soup.select](http://soup.select)("태그명")를 통해 원하는 태그에 접근한다
- 새 리스트를 만들고 pd.read_html( )[ ]을 통해 행을 하나씩 추가한다
- pd.concat으로 행을 합쳐 데이터 프레임으로 만들면 데이터 수집이 끝난다

### 수집할 url 찾는 방법 2가지

- 단순히 데이터의 웹 사이트에 들어가서 url을 복사 붙여넣기
- 크롬의 검사 - 네트워크 탭의 doc의 문서 클릭 - request url 확인, request method 확인

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f7cebce2-f140-4583-a1da-ac00545b7124/1.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/f7cebce2-f140-4583-a1da-ac00545b7124/1.png)

- 첫 번째 방법에서 원하는 데이터를 가져오지 못하는 경우, 두 번째 방법 시도

### requests를 통한 http 요청

- request method를 보고 get 혹은 post를 결정
- get: url 전송(url에 검색어 포함 x), post: 폼 전송 (url에 검색어가 포함됨)
- user-agent값을 header로 지정해 header 옵션을 주면 에러없이 데이터를 불러올 수 있다

![https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6432e1de-5425-49a9-8a1d-6444489eda6c/2.png](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/6432e1de-5425-49a9-8a1d-6444489eda6c/2.png)

### pandas 코드로 데이터 수집하기

- read_html을 이용해 url의 page내의 값을 데이터프레임 형태로 받아 올 수 있다
- 한글 인코딩을 위해 encoding 옵션을 'cp949'로 입력
- pd.read_html( )

    괄호 안에 들어가는 값은 str 형태여야 한다

### Json 타입 데이터 수집 방법

- text 타입과 마찬가지로 requests method를 확인, response 200(정상) 값을 확인한다
- response 200이 뜨면 .json( )을 이용해 json 타입으로 데이터를 받는다
- 인덱싱을 이용하여 json 타입 데이터에서 원하는 데이터를 추출하고 새 변수에 넣어준다
- 보기 좋게 데이터 프레임 형태로 바꾸기 위해 pandas의 DataFrame 함수를 이용해 데이터 프레임 형태로 바꿔준다

### 중복데이터 제거하기

- drop_duplicates( )를 통해 중복된 데이터를 제거할 수 있다
- row들끼리 data를 비교해 같은 값이 있으면 row 중 하나의 값만 출력해준다
